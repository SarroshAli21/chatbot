# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bHOLpFXQUo_4_aPJV1kHa4eJE2oA2eMo
"""

!pip install streamlit lightfm pandas scikit-learn
import streamlit as st
import pandas as pd
import numpy as np  # Make sure to import numpy
from lightfm import LightFM
from lightfm.evaluation import precision_at_k
import scipy.sparse as sp

# Step 2: Save the following Python code into a Python file (e.g., app.py)
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Load the data without caching for now (due to potential cache-related issues)
def load_data():
    folder_path = '/content/drive/MyDrive/tahir Thesis data/'  # Add correct path to your data files
    ratings = pd.read_csv(folder_path + 'ratings.csv')
    movies = pd.read_csv(folder_path + 'movies.csv')
    return ratings, movies

ratings, movies = load_data()

# Convert to categorical codes
user_ids = ratings['userId'].astype('category').cat.codes
movie_ids = ratings['movieId'].astype('category').cat.codes
rating_values = ratings['rating'].values

# Create the interaction matrix
interaction_matrix = sp.coo_matrix((rating_values, (user_ids, movie_ids)))

# Step to ensure the interaction matrix is writable
interaction_matrix = sp.csr_matrix(interaction_matrix.copy())

# Train the LightFM model without caching to avoid read-only errors
def train_model():
    model = LightFM(loss='warp')
    model.fit(interaction_matrix, epochs=10, num_threads=2)
    return model

model = train_model()

# Create a simple user interface
st.title('Movie Recommender System')

# Select a movie from the available titles
selected_movie = st.selectbox('Select a movie to get recommendations:', movies['title'])

# Find the movie ID
movie_row = movies[movies['title'] == selected_movie]

# Check if the selected movie exists
if not movie_row.empty:
    movie_id = movie_row['movieId'].values[0]

    # Safely find the movie index in the DataFrame
    try:
        movie_idx = movies[movies['movieId'] == movie_id].index[0]

        # Generate recommendations
        def recommend(model, movie_idx, num_recommendations=5):
            scores = model.predict(np.arange(interaction_matrix.shape[0]), np.repeat(movie_idx, interaction_matrix.shape[0]))
            top_recommendations = np.argsort(-scores)[:num_recommendations]
            recommended_movie_ids = [movies.iloc[i]['movieId'] for i in top_recommendations]
            return recommended_movie_ids

        # Show recommendations
        recommended_movie_ids = recommend(model, movie_idx)
        st.write("Top recommended movies:")
        recommended_movies = movies[movies['movieId'].isin(recommended_movie_ids)]
        st.write(recommended_movies[['title']])

    except IndexError:
        st.error(f"Movie with ID {movie_id} not found in the dataset.")
else:
    st.error(f"The selected movie '{selected_movie}' was not found in the database.")

from lightfm import LightFM
from lightfm.cross_validation import random_train_test_split
from lightfm.evaluation import precision_at_k, recall_at_k, auc_score

# Create the interaction matrix (same as before)
interaction_matrix = sp.coo_matrix((rating_values, (user_ids, movie_ids)))

# Split the interaction matrix into training and testing sets using LightFM's built-in method
train_interactions, test_interactions = random_train_test_split(interaction_matrix, test_percentage=0.2, random_state=42)

# Train the model
model = LightFM(loss='warp')
model.fit(train_interactions, epochs=10, num_threads=2)

# Function to evaluate the model
def evaluate_model(model, train_interactions, test_interactions):
    # Precision@K
    test_precision = precision_at_k(model, test_interactions, k=10).mean()
    # Recall@K
    test_recall = recall_at_k(model, test_interactions, k=10).mean()
    # AUC score
    test_auc = auc_score(model, test_interactions).mean()

    # Print evaluation metrics
    st.write(f"Model Evaluation Results:")
    st.write(f"Precision@10: {test_precision:.4f}")
    st.write(f"Recall@10: {test_recall:.4f}")
    st.write(f"AUC Score: {test_auc:.4f}")

# Evaluate the model
evaluate_model(model, train_interactions, test_interactions)

import matplotlib.pyplot as plt
import numpy as np
from lightfm.evaluation import precision_at_k, recall_at_k
from sklearn.metrics import precision_recall_curve, roc_curve, auc

# Function to plot precision and recall at different K values
def plot_precision_recall_vs_k(model, train_interactions, test_interactions, k_values):
    precision_scores = []
    recall_scores = []

    for k in k_values:
        precision = precision_at_k(model, test_interactions, k=k).mean()
        recall = recall_at_k(model, test_interactions, k=k).mean()
        precision_scores.append(precision)
        recall_scores.append(recall)

    # Plot Precision@K and Recall@K
    plt.figure(figsize=(10, 6))
    plt.plot(k_values, precision_scores, label="Precision@K", marker='o')
    plt.plot(k_values, recall_scores, label="Recall@K", marker='o')

    plt.title("Precision and Recall vs K")
    plt.xlabel("K (Top K Recommendations)")
    plt.ylabel("Score")
    plt.legend()
    plt.grid()
    plt.show()

# Function to plot Precision-Recall Curve
def plot_precision_recall_curve(model, test_interactions):
    y_true = test_interactions.toarray().flatten()
    y_scores = model.predict(test_interactions.row, test_interactions.col)

    precision, recall, _ = precision_recall_curve(y_true, y_scores)

    # Plot the precision-recall curve
    plt.figure(figsize=(10, 6))
    plt.plot(recall, precision, label="Precision-Recall Curve", color='b')

    plt.title("Precision-Recall Curve")
    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.grid()
    plt.legend()
    plt.show()

# Function to plot ROC Curve and AUC
def plot_roc_curve(model, test_interactions):
    y_true = test_interactions.toarray().flatten()
    y_scores = model.predict(test_interactions.row, test_interactions.col)

    fpr, tpr, _ = roc_curve(y_true, y_scores)
    roc_auc = auc(fpr, tpr)

    # Plot ROC curve
    plt.figure(figsize=(10, 6))
    plt.plot(fpr, tpr, label=f"ROC Curve (AUC = {roc_auc:.4f})", color='b')

    plt.title("ROC Curve")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.grid()
    plt.legend()
    plt.show()

# Function to plot loss over epochs
def plot_loss_over_epochs(model, train_interactions, epochs):
    losses = []
    for epoch in range(epochs):
        loss = model.fit_partial(train_interactions, epochs=1, num_threads=2)
        losses.append(loss)

    # Plot loss over epochs
    plt.figure(figsize=(10, 6))
    plt.plot(range(1, epochs + 1), losses, marker='o')
    plt.title("Loss Over Epochs")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.grid()
    plt.show()

# Visualize Precision and Recall at different K values
k_values = [1, 5, 10, 20, 50]
plot_precision_recall_vs_k(model, train_interactions, test_interactions, k_values)

# Visualize Precision-Recall Curve
plot_precision_recall_curve(model, test_interactions)

# Visualize ROC Curve and AUC
plot_roc_curve(model, test_interactions)

# Visualize Loss over Epochs
epochs = 10  # Same as your training epochs
plot_loss_over_epochs(model, train_interactions, epochs)

